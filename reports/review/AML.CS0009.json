{
    "data_type": "AVID",
    "data_version": null,
    "metadata": null,
    "affects": {
        "developer": [],
        "deployer": [
            "Microsoft's Tay AI Chatbot"
        ],
        "artifacts": {
            "type": "system",
            "name": "Microsoft's Tay AI Chatbot"
        }
    },
    "problemtype": {
        "classof": "ATLAS Case Study",
        "type": "Advisory",
        "description": {
            "lang": "eng",
            "value": "Tay Poisoning"
        }
    },
    "metrics": null,
    "references": [
        {
            "type": "source",
            "label": "Tay Poisoning",
            "url": "https://atlas.mitre.org/studies/AML.CS0009"
        },
        {
            "type": "source",
            "label": "AIID - Incident 6: TayBot",
            "url": "https://incidentdatabase.ai/cite/6"
        },
        {
            "type": "source",
            "label": "Microsoft BlogPost, \"Learning from Tay's introduction\"",
            "url": "https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/"
        },
        {
            "type": "source",
            "label": "IEEE Article, \"In 2016, Microsoft's Racist Chatbot Revealed the Dangers of Online Conversation\"",
            "url": "https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation"
        }
    ],
    "description": {
        "lang": "eng",
        "value": "Microsoft created Tay, a Twitter chatbot designed to engage and entertain users.\nWhile previous chatbots used pre-programmed scripts\nto respond to prompts, Tay's machine learning capabilities allowed it to be\ndirectly influenced by its conversations.\n\nA coordinated attack encouraged malicious users to tweet abusive and offensive language at Tay,\nwhich eventually led to Tay generating similarly inflammatory content towards other users.\n\nMicrosoft decommissioned Tay within 24 hours of its launch and issued a public apology\nwith lessons learned from the bot's failure.\n"
    },
    "impact": null,
    "credit": {
        "lang": "eng",
        "value": "Microsoft"
    },
    "reported_date": "2016-03-23"
}