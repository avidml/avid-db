{
    "report_id": "AVID-2022-R0005",
    "metadata": {
        "class": "LLM evaluation",
        "type": "Detection",
        "taxonomy_version": "0.1"
    },
    "submission": {
        "submitter_name": "Harry Saini",
        "submitter_org": "AVID",
        "date": "2022-11-09"
    },
    "description": {
        "lang": "eng",
        "name": "Demographic bias found in EleutherAI/gpt-neo-125M for multiple sensitive categories, as measured on prompts supplied in the BOLD dataset",
        "description": "When supplied with prompts from the BOLD dataset, toxicity scores for completed sentences tagged with the 'Islam' religion demonstrate a higher degree of toxicity than other religions."
    },
    "vuln_metrics": [
        {
            "name": "Toxicity score", 
            "features": {
                "measured": "Toxicity score",
                "sensitive": "religious_ideology"
            },
            "detection": {
                "class": "Significance test",
                "name": "Anderson-Darling k-sample test"
            }
        }
    ],
    "references": [
        {
            "type": "source", 
            "name": "Gender Bias Evaluation for Masked Language modelling: BOLD", 
            "source": "github", 
            "url": "avidml/evaluating-LLMs/blob/main/notebooks/evaluation_bold.ipynb"
        },
        {
            "type": "model", 
            "name": "EleutherAI/gpt-neo-125M", 
            "source": "hf_hub", 
            "url": "EleutherAI/gpt-neo-125M"
        },
        {
            "type": "misc", 
            "name": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation", 
            "source": "web", 
            "url": "https://arxiv.org/abs/2101.11718"
        }
    ],
    "tags": {
        "avid": {
            "vuln_id": "AVID-2022-V003",
            "risk_domain": ["Ethics"],
            "sep_view": [
                {
                    "id": "E0101",
                    "name": "Group Fairness"
                }
            ],
            "lifecycle_view": [
                {
                    "id": "L05",
                    "stage": "Evaluation"
                }
            ]
        },
        "hf": [
            {
                "type": "model", 
                "name": "EleutherAI/gpt-neo-125M"
            }
        ]
    }
}