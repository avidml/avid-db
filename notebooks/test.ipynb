{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbd23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json2html import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec01fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = json.load(open('./vulnerabilities/2022/AVID-2022-V001.json'))\n",
    "j = json.load(open('Untitled.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5144500",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8138006d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>vuln_id</th><td>AVID-2022-V001</td></tr><tr><th>metadata</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>class</th><td>LLM evaluation</td></tr><tr><th>taxonomy_version</th><td>0.1</td></tr></table></td></tr><tr><th>description</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>lang</th><td>eng</td></tr><tr><th>name</th><td>Gender Bias in Sentence Completion Tasks performed by bert-base-uncased</td></tr><tr><th>value</th><td>xyz xyz</td></tr></table></td></tr><tr><th>reports</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><thead><tr><th>report_id</th><th>class</th><th>name</th></tr></thead><tbody><tr><td>AVID-2022-R0001</td><td>Measurement</td><td>Gender Bias in sentence completion Tasks performed by bert-base-uncased using the HONEST metric</td></tr><tr><td>AVID-2022-R0003</td><td>Measurement</td><td>Profession bias reinforcing gender stereotypes found in bert-base-uncased, as measured on the Winobias dataset</td></tr></tbody></table></td></tr><tr><th>references</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><thead><tr><th>label</th><th>url</th></tr></thead><tbody><tr><td>bert-base-uncased on Hugging Face</td><td>https://huggingface.co/bert-base-uncased</td></tr></tbody></table></td></tr><tr><th>tags</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>avid</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>risk_domain</th><td><ul><li>Ethics</li></ul></td></tr><tr><th>sep_id</th><td><ul><li>E0101</li></ul></td></tr><tr><th>lifecycle_stage</th><td><ul><li>Evaluation</li></ul></td></tr><tr><th>lifecycle_stage_id</th><td><ul><li>L05</li></ul></td></tr></table></td></tr><tr><th>hf</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>model_name</th><td>bert-base-uncased</td></tr></table></td></tr><tr><th>config</th><td><table id=\"info-table\" class=\"table table-bordered table-hover\"><tr><th>application</th><td></td></tr><tr><th>task</th><td><ul><li>Masked Language Modelling</li></ul></td></tr><tr><th>architecture</th><td><ul><li>BertForMaskedLM</li><li>Transformer</li></ul></td></tr></table></td></tr></table></td></tr></table>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json2html.convert(json = j, table_attributes=\"id=\\\"info-table\\\" class=\\\"table table-bordered table-hover\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03eae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.load(open('test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b76c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Person\n",
      "\n",
      "*JSON Schema for a person object.*\n",
      "\n",
      "## Properties\n",
      "\n",
      "- **`firstName`** *(string)*: The person's first name.\n",
      "- **`lastName`** *(string)*: The person's last name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jsonschema2md\n",
    "\n",
    "parser = jsonschema2md.Parser(\n",
    "    examples_as_yaml=False,\n",
    "    show_examples=\"all\",\n",
    ")\n",
    "md_lines = parser.parse_schema(j)\n",
    "print(''.join(md_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d9de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyairtable\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('AIRTABLE_API_KEY')\n",
    "config = json.load(open('../connectors/config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cde58cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from airtable\n",
    "all_data = pyairtable.Table(api_key, config['airtable']['base_id'], config['airtable']['table_name']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69efe000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_report(record):\n",
    "    \n",
    "    report = {}\n",
    "    report['data_type'] = 'AVID'\n",
    "    report['version'] = ''\n",
    "    report['metadata'] = {\n",
    "        'report_id' : ''\n",
    "    }\n",
    "    report['affects'] = {\n",
    "        'developer': record['fields']['Developer of Artifact'],\n",
    "        'deployer': record['fields']['Deployer of Artifact'],\n",
    "        'artifact': [\n",
    "            {\n",
    "                'type': record['fields']['Artifact Type'],\n",
    "                'name': record['fields']['Artifact Name']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    report['problemtype'] = {\n",
    "        'class': '',\n",
    "        'type': record['fields']['Report Type'].split(':')[0],\n",
    "        'description': {\n",
    "            'lang': 'eng',\n",
    "            'value': record['fields']['Title']\n",
    "        }\n",
    "    }\n",
    "    report['metrics'] = []\n",
    "    report['references'] = record['fields']['References']\n",
    "    report['description'] = {\n",
    "        'lang': 'eng',\n",
    "        'value': record['fields']['Description']\n",
    "    }\n",
    "    report['impact'] = {\n",
    "        'avid': {\n",
    "            'vuln_id': '',\n",
    "            'risk_domain': record['fields']['Relevant SEP risk domains'],\n",
    "            'sep_view': record['fields']['Relevant Ethics subcategories'],\n",
    "            'lifecycle_view': record['fields']['Relevant stages of the AI lifecycle']\n",
    "        }\n",
    "    }\n",
    "    report['credits'] = [\n",
    "        {\n",
    "            'lang': 'eng',\n",
    "            'value': record['fields']['Submitter Name']\n",
    "        }\n",
    "    ]\n",
    "    report['reported_date'] = record['createdTime'].split('T')[0]\n",
    "    \n",
    "    # save report\n",
    "    output = open('../reports/dev/'+record['id']+'.json', 'w')\n",
    "    json.dump(report, output, indent=4)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f93d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'reciaOOxqMH4eCkOq',\n",
       " 'createdTime': '2023-01-05T02:22:03.000Z',\n",
       " 'fields': {'Developer of Artifact': 'OpenAI',\n",
       "  'Deployer of Artifact': 'OpenAI',\n",
       "  'Description': 'I asked ChatGPT to recommend papers on explainability, privacy, adversarial ML, etc. It did recommend me a list of papers but it linked wrong authors to the papers and some of the papers didn\\'t even exist (maybe it just made up those paper titles). For example- when prompted to recommend papers on explainability, it said the paper \"Explaining Explanations: An Overview of Interpretability of Machine Learning\" is by Zach Lipton, which in fact, is written by Gilpin et al. and does not have Zach as an author. This potentially hints at misinformation. It made similar mistakes when asking for papers on privacy, interpretability, and adversarial ML. ',\n",
       "  'Submission Date': '2023-01-04',\n",
       "  'Artifact Type': 'Model',\n",
       "  'Relevant SEP risk domains': ['Ethics'],\n",
       "  'Report Type': 'Issue: qualitative evaluation based on a small sample',\n",
       "  'Submitter e-mail': 'jaijborkar@gmail.com',\n",
       "  'Submitter Name': 'Jaydeep Borkar',\n",
       "  'Title': 'ChatGPT links wrong authors to papers',\n",
       "  'Relevant stages of the AI lifecycle': ['L05: Evaluation',\n",
       "   'L06: Deployment'],\n",
       "  'References': 'The results can be reproduced by using the prompt \"Can you recommend any papers on explainability?\". I think the developers might have fixed this issue after realizing this. So it might say something along the lines of \"Sorry, I cannot recommend any papers\". But I have screenshots if needed. ',\n",
       "  'Artifact Name': 'ChatGPT',\n",
       "  'Relevant Ethics subcategories': ['E0402: Generative Misinformation']},\n",
       " 'Submitter Organization': '',\n",
       " 'Relevant Security subcategories': '',\n",
       " 'Relevant Performance subcategories': ''}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = all_data[3].copy()\n",
    "\n",
    "# fill essential empty entries\n",
    "record_keys = list(record['fields'].keys())\n",
    "strings = ['Submitter Organization'] + ['Relevant '+s+' subcategories' for s in ['Security','Ethics','Performance']]\n",
    "for st in strings:\n",
    "    if record_keys.count(st)==0:\n",
    "        record[st] = ''\n",
    "\n",
    "record"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
