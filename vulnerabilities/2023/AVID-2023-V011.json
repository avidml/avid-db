{
    "data_type": "AVID",
    "data_version": "0.2",
    "metadata": {
        "vuln_id": "AVID-2023-V011"
    },
    "affects": {
        "developer": [],
        "deployer": [
            "New Microsoft AI Product"
        ],
        "artifacts": [
            {
                "type": "System",
                "name": "New Microsoft AI Product"
            }
        ]
    },
    "problemtype": {
        "classof": "ATLAS Case Study",
        "type": "Advisory",
        "description": {
            "lang": "eng",
            "value": "Microsoft Edge AI Evasion"
        }
    },
    "references": [
        {
            "type": "source",
            "label": "Microsoft Edge AI Evasion",
            "url": "https://atlas.mitre.org/studies/AML.CS0011"
        }
    ],
    "description": {
        "lang": "eng",
        "value": "The Azure Red Team performed a red team exercise on a new Microsoft product designed for running AI workloads at the edge. This exercise was meant to use a automated system to continuously manipulate a target image to cause the ML model to produce misclassifications.\n"
    },
    "reports": null,
    "impact": {
        "avid": {
            "risk_domain": [
                "Security"
            ],
            "sep_view": [
                "S0301: Information Leak",
                "S0403: Adversarial Example"
            ],
            "lifecycle_view": [
                "L06: Deployment"
            ],
            "taxonomy_version": "0.2"
        }
    },
    "credit": null,
    "published_date": "2023-03-31",
    "last_modified_date": "2023-03-31"
}