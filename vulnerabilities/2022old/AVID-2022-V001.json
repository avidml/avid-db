{
    "vuln_id": "AVID-2022-V001",
    "metadata": {
        "class": "LLM evaluation",
        "taxonomy_version": "0.1"
    },
    "description": {
        "lang": "eng",
        "name": "Gender Bias in Sentence Completion Tasks performed by bert-base-uncased",
        "value": "xyz xyz"
    },
    "reports": [
        {
            "report_id": "AVID-2022-R0001",
            "class": "Detection",
            "name": "Gender Bias in Sentence Completion Tasks performed by bert-base-uncased using the HONEST metric"
        },
        {
            "report_id": "AVID-2022-R0003",
            "class": "Detection",
            "name": "Profession bias reinforcing gender stereotypes found in bert-base-uncased, as measured on the Winobias dataset"
        }
    ],
    "references": [
        {
            "label": "bert-base-uncased on Hugging Face",
            "url": "https://huggingface.co/bert-base-uncased"
        }          
    ],
    "tags": {
        "avid": {
            "risk_domain": ["Ethics"],
            "sep_view": [
                {
                    "id": "E0101",
                    "name": "Group Fairness"
                }
            ],
            "lifecycle_view": [
                {
                    "id": "L05",
                    "stage": "Evaluation"
                }
            ]
        },
        "hf": [
            {
                "type": "model",
                "name": "bert-base-uncased"
            }
        ],
        "config": {
            "application": [],
            "task": ["Masked Language Modelling"],
            "architecture": [
                "BertForMaskedLM",
                "Transformer"
            ]
        }
    }
}