{
    "vuln_id": "AVID-2022-V003",
    "metadata": {
        "class": "LLM evaluation",
        "taxonomy_version": "0.1"
    },
    "description": {
        "lang": "eng",
        "name": "Multiple fairness harms found in generated text from EleutherAI/gpt-neo-125M",
        "value": "xyz xyz"
    },
    "reports": [
        {
            "report_id": "AVID-2022-R0005",
            "class": "Detection",
            "name": "Demographic bias found in EleutherAI/gpt-neo-125M for multiple sensitive categories, as measured on prompts supplied in the BOLD dataset"
        }
    ],
    "references": [
        {
            "label": "gpt-neo-125M on Hugging Face",
            "url": "https://huggingface.co/EleutherAI/gpt-neo-125M"
        }
    ],
    "tags": {
        "avid": {
            "risk_domain": ["Ethics"],
            "sep_view": [
                {
                    "id": "E0101",
                    "name": "Group Fairness"
                }
            ],
            "lifecycle_view": [
                {
                    "id": "L05",
                    "stage": "Evaluation"
                }
            ]
        },
        "hf": [
            {
                "type": "model",
                "name": "EleutherAI/gpt-neo-125M"
            }
        ],
        "config": {
            "application": [],
            "task": ["Masked Language Modelling"],
            "architecture": [
                "GPTNeoForCausalLM",
                "Transformer"
            ]
        }
    }
}