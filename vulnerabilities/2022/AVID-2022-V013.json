{
    "vuln_id": "AVID-2022-V013",
    "metadata": {
        "event_class": {
            "entity": "System",
            "function": "Inference"
        },
        "vuln_class": "AIID incident",
        "taxonomy_version": "0.1"
    },
    "description": {
        "lang": "eng",
        "name": "TayBot",
        "value": "Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semetic tweets generated by the bot."
    },
    "reports": [],
    "references": [
        {
            "label": "Incident 6: TayBot",
            "url": "https://incidentdatabase.ai/cite/6"
        },
        {
            "label": "Tay Poisoning",
            "url": "https://atlas.mitre.org/studies/AML.CS0009"
        }
    ],
    "tags": {
        "avid": {
            "risk_domain": ["Security","Ethics"],
            "sep_id": ["S0601","E0101","E0301"],
            "lifecycle_stage": ["Data Preparation"],
            "lifecycle_stage_id": ["L03"]
        },
        "aiid": {
            "incident_id": "AIID0006",
            "report_count": 26,
            "incident_date": "2016-03-24",
            "editors": "Sean McGregor",
            "named_entities": ["Microsoft", "Twitter", "Tay", "Xiaoice"]
        },
        "config": {
            "deployer": ["Microsoft"],
            "application": ["Arts, entertainment and recreation", "comprehension", "language output", "chatbot"],
            "task": ["content creation", "language recognition", "natural language processing","generative"]
        }
    }
}